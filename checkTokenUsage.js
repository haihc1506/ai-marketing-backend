require('dotenv').config();
const readline = require('readline');

// C·∫•u h√¨nh ƒë·ªçc input t·ª´ d√≤ng l·ªánh
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

const apiKey = process.env.GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;

if (!apiKey) {
  console.error("‚ùå L·ªñI: Ch∆∞a t√¨m th·∫•y API KEY trong file .env");
  process.exit(1);
}

// H√†m l·∫•y danh s√°ch model v√† gi·ªõi h·∫°n c·ªßa ch√∫ng
async function getModels() {
  const url = `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`;
  try {
    const response = await fetch(url);
    const data = await response.json();
    return data.models || [];
  } catch (error) {
    console.error("L·ªói l·∫•y danh s√°ch model:", error);
    return [];
  }
}

// H√†m t√≠nh to√°n token cho m·ªôt ƒëo·∫°n text c·ª• th·ªÉ
async function countTokens(modelName, text) {
  // L∆∞u √Ω: Endpoint countTokens th√™m h·∫≠u t·ªë :countTokens
  const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:countTokens?key=${apiKey}`;
  
  const payload = {
    contents: [{
      parts: [{ text: text }]
    }]
  };

  try {
    const response = await fetch(url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(payload)
    });
    const data = await response.json();
    return data.totalTokens; // Tr·∫£ v·ªÅ s·ªë token ƒë√£ d√πng
  } catch (error) {
    console.error(`L·ªói ƒë·∫øm token model ${modelName}:`, error);
    return null;
  }
}

async function main() {
  console.log("üì° ƒêang l·∫•y th√¥ng tin models...");
  const models = await getModels();
  
  // L·ªçc l·∫•y c√°c model chat/generate ph·ªï bi·∫øn
  const chatModels = models.filter(m => 
    m.supportedGenerationMethods.includes("generateContent") &&
    (m.name.includes("flash") || m.name.includes("pro"))
  );

  if (chatModels.length === 0) {
    console.log("‚ùå Kh√¥ng t√¨m th·∫•y model ph√π h·ª£p.");
    process.exit(1);
  }

  console.log("\n‚úÖ ƒê√£ t√¨m th·∫•y c√°c model. B√¢y gi·ªù h√£y nh·∫≠p n·ªôi dung b·∫°n mu·ªën ki·ªÉm tra.");
  console.log("   (V√≠ d·ª•: Prompt d√†i b·∫°n ƒë·ªãnh g·ª≠i cho AI, ho·∫∑c n·ªôi dung file text...)");
  
  rl.question('\nüìù Nh·∫≠p text c·ªßa b·∫°n: ', async (userInput) => {
    if (!userInput) {
      console.log("B·∫°n ch∆∞a nh·∫≠p g√¨ c·∫£.");
      process.exit(0);
    }

    console.log("\n-------- K·∫æT QU·∫¢ T√çNH TO√ÅN TOKEN --------");
    console.log(`ƒê·ªô d√†i vƒÉn b·∫£n: ${userInput.length} k√Ω t·ª±`);
    console.log("-".repeat(80));
    console.log(`| ${"MODEL".padEnd(25)} | ${"ƒê√É D√ôNG".padEnd(10)} | ${"T·ªîNG LIMIT".padEnd(15)} | ${"C√íN L·∫†I".padEnd(15)} |`);
    console.log("-".repeat(80));

    // Ch·∫°y v√≤ng l·∫∑p ki·ªÉm tra t·ª´ng model
    for (const model of chatModels) {
      const modelName = model.name.replace("models/", "");
      const inputLimit = model.inputTokenLimit;
      
      // G·ªçi API ƒë·∫øm token th·ª±c t·∫ø
      const usedTokens = await countTokens(modelName, userInput);

      if (usedTokens !== null) {
        const remaining = inputLimit - usedTokens;
        const percentUsed = ((usedTokens / inputLimit) * 100).toFixed(4); // Hi·ªÉn th·ªã 4 s·ªë th·∫≠p ph√¢n v√¨ limit r·∫•t l·ªõn

        // Format s·ªë cho ƒë·∫πp (1,000,000)
        const fmtUsed = usedTokens.toLocaleString();
        const fmtLimit = inputLimit.toLocaleString();
        const fmtRem = remaining.toLocaleString();

        console.log(`| ${modelName.padEnd(25)} | ${fmtUsed.padEnd(10)} | ${fmtLimit.padEnd(15)} | ${fmtRem.padEnd(15)} |`);
        
        // C·∫£nh b√°o n·∫øu d√πng nhi·ªÅu
        if (remaining < 0) console.log(`  ‚ö†Ô∏è QU√Å T·∫¢I: B·∫°n ƒë√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n c·ªßa model n√†y!`);
      }
    }
    console.log("-".repeat(80));
    console.log("üí° 'ƒê√É D√ôNG': S·ªë token API t√≠nh cho ƒëo·∫°n text n√†y.");
    console.log("üí° 'C√íN L·∫†I': Dung l∆∞·ª£ng b·ªô nh·ªõ c√≤n tr·ªëng trong 1 request (Context Window).");
    
    rl.close();
  });
}

main();